\section{Acquisition of data}
% Introduce and group ATLAS+CMS+ALICE/LHCb
The first stage of any trigger system involves the readout of detector information (e.g.,  energy deposits in a calorimeter/tracker) and subsequent processing of this information. This processing has two main facets: the synchronisation of information, to ensure that corresponding data from separate subdetectors are correctly associated and the reduction of data volume. The latter is generally accomplished through a combination of basic compression techniques (e.g.,  zero suppression) and simple selections. This is the common task of a low-level trigger. This section covers ATLAS, CMS and ALICE, as LHCb no longer employs a low-level triggerâ€”detector information is read out continuously by TELL40 readout boards (with compression applied upon readout) and passed to the event builder InfiniBand-based network of HLT1~\cite{LHCb:2023hlw}.

%Large ATLAS on tiered trig sys, similar structure in CMS, slight difference in ALICE, then tiny LHCb caveat/sentence to be discussed later

%ATLAS+CMS+ALICE
The initial hardware-based L1 triggers of ATLAS~\cite{ATLASRun3Detector} and CMS~\cite{cms2023development} both reduce the rate of data down to a maximum detector read out limit of \SI{100}{\kilo\hertz}, within a latency of \SI{2.5}{\micro\second} at ATLAS and \SI{4}{\micro\second} at CMS. The systems consist of custom ASIC- and FPGA-based\footnote{Algorithm Specific Integrated Chips and Field Programmable Gate Arrays, respectively~\cite{asics-fpgas}.} electronics which use reduced granular information from the calorimeter and muon systems to perform coarse selections. Upon an event passing this selection, the L1 directs the readout hardware of each subdetector to process the data stored in associated buffers. Event information from each subdetector is processed, combined and formatted within the readout system, where it is buffered until requested by the HLT, acting as a throttling system to remain within the constraints given by the detector read-out latency.

The data acquisition (DAQ) systems of both experiments have evolved to use consumer network and computing hardware downstream of custom on-board electronics. This setup simplifies the readout in complexity, maintenance cost and upgrade capabilities. At ATLAS the Front-End LInk eXchange (FELIX)~\cite{ATLAS:FELIX} readout boards, responsible for the interface between commercial and custom hardware, have been partially implemented and will be fully implemented for HL-LHC.

%ALICE Copied and restructured from previous version.
In Run~3, several of the ALICE subdetectors have been upgraded to read out data continuously. The CTS synchronises data, subdividing readout into HeartBeat (HB) frames of approximately 1 LHC orbit period ($\sim\SI{88.92}{\micro\second}$). An HB frame is only kept if all relevant readout units (up to 441 in the entire detector) can be read out. Each HB decision is transmitted asynchronously to the First Level Processor, instructing it on what data to keep in a given HB frame. Whilst many subdetectors (including the TPC) were upgraded to read out data continuously in Run~3, continuous readout is not possible for several subdetectors, e.g.,  the Transition Radiation Detector. Such subdetectors are operated on a triggered basis and are hence excluded from the HB decision calculation, instead using the existing RD12 TTC protocol developed for Run~2 operation. Triggered subdetectors thus operate independently, with triggered data combined with continuous readout data at a later stage~\cite{alice-trigger-run3}.

