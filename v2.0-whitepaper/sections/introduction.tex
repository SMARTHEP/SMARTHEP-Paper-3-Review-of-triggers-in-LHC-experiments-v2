\section{Introduction}

%Intro
To enable the study of physical phenomena with extremely small cross-sections and reach the ultimate precision in measurements of more common processes, the Large Hadron Collider (LHC) was designed to operate at the highest possible energy and luminosity~\cite{CERN:lhc-design-report}. Protons are accelerated to an energy of \SI{6.8}{\tera\electronvolt}, grouped into bunches in opposing beams which cross one another every \SI{25}{\nano\second} \cite{CERN:lhc-run3-operation}. Capturing the detail of proton-proton ($pp$) collisions at a rate of \SI{40}{\mega\hertz} introduces an immense data challenge, in which recording collisions in full detail at a typical LHC experiment would require transferring and writing data at up to ${\sim}\SI{40}{\tera\byte\per\second}$. To reduce this data flow, High Energy Physics (HEP) experiments employ trigger systems: computing systems designed to perform detector data readout, event-building, selection, etc in real time as to reduce the throughput to a manageable level. Typically, $\mathcal{O}\left(\SI{1}{\giga\byte\per\second}\right)$ of data useful to the physics goals of an experiment is written to permanent storage.

Each LHC experiment discussed in this paper—ALICE, ATLAS, CMS and LHCb—has undertaken considerable research and development in the field of triggers and data acquisition (TDAQ). Developments in computational resources (e.g., the adoption of hybrid architectures) and data processing approaches (e.g., real-time and parallelised software frameworks) have enabled more advanced trigger systems to be developed in recent years. These trigger systems are capable of performing real-time calibration, high-level monitoring, etc. ALICE and LHCb performed significant upgrades to their trigger systems ahead of Run~3 of the LHC (2022-2025), with ATLAS and CMS planning upgrades of similar scales ahead of the High-Luminosity LHC (HL-LHC) operational period (2029-2040s). In this paper, the current trigger state-of-the art is reviewed, predominantly within the context of the current Run~3 data-taking period.

% Overview of trigger strategies
% Model detector, what does a non-specific trigger look like?
\subsection{Principles of triggering in High Energy Physics}

The primary function of a trigger system, as laid out in Figure~\ref{trigger-schema}, is to reduce the data rate that must be processed without impairing the physics performance of the experiment~\cite{Jeitler_2017, Smith2020, Beck_2007, ellis2010trigger}. The performance of a trigger system is therefore determined by the optimisation of three quantities: high signal efficiency, high background rejection (or equivalently low background efficiency) and affordable throughput/output bandwidth. Furthermore, this performance must be quantifiable (e.g., that trigger efficiencies are calculable), robust and deterministic. To satisfy these requirements, triggers are typically designed in a tiered structure: a hardware-based (low-level) tier performs detector readout, initial data reduction and coarse selection; a software-based (high-level) tier performs reconstruction of event objects and further selection based on these objects.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/trigger_schematic.pdf}
    \caption[A generalised schematic of a trigger system for a HEP experiment in the current paradigm. Raw data is read out from each subdetector. A low-level (hardware) trigger is typically employed to synchronise readout and apply initial selection/compression algorithms. A high-level (software) trigger makes further selections on reconstructed objects of increasing accuracy, which are then saved for offline analysis. Alignment and calibration are often performed alongside the high-level trigger to inform the reconstruction algorithms required for detailed selections.]{A generalised schematic of a trigger system for an HEP experiment in the current paradigm. Raw data is read out from each subdetector. A low-level (hardware) trigger is typically{\protect\footnotemark} employed to synchronise readout and apply initial selection/compression algorithms. Low-level trigger information and detector readout/reconstructed objects are combined in an event building stage. A high-level (software) trigger makes further selections on reconstructed objects of increasing accuracy, which are then saved for offline analysis. Alignment and calibration are often performed alongside the high-level trigger to inform the reconstruction algorithms required for detailed selections.}
    \label{trigger-schema}
\end{figure}
\footnotetext{LHCb does not employ a low-level trigger in Run~3~\cite{LHCb_upgrade_trigger_TDR} and the ALICE low-level trigger does not apply selection~\cite{alice-trigger-run3}.}

A low-level trigger must operate at a rate close to the collision rate of \SI{40}{\mega\hertz} and thus must have a minimal dead time between operations. The low-level trigger operates in a staged configuration, increasing latency with each stage to enable more detailed (and thus slower) operations to be performed on the data. However, even the highest latency levels of a low-level trigger generally require custom high-speed electronics to perform operations. The data processed by the low-level trigger, typically reduced in rate by a factor $\mathcal{O}\left(100\right)$, is then passed to the high-level trigger for more detailed processing.

High-level triggers must perform more complex and computationally intensive tasks such as event reconstruction and calibration. To ensure that such tasks can be performed at the low-level trigger output rate, the high-level trigger is usually separated into two tiers, with the first performing coarse reconstruction and initial selections requiring simpler reconstructed objects (e.g., tracks), and the second performing a detailed reconstruction for more complex selections. High-level triggers typically take the form of a computing farm, making use of parallel computing approaches to efficiently distribute tasks across the available computing resources.

The implementations of such systems in each of the major LHC experiments are introduced in the following sections.

%It is difficult to satisfy both the high efficiencies and high background rejection physics requirements, as well as the very small trigger latency to reduce dead time. Multi-trigger systems are usually introduced. The Level-1 (L1) Trigger is a hardware trigger, comprised of custom high-speed electronics, which makes decisions based off of coarsely reconstructed subset of information from the detector. The L1 trigger renders a selection decision every bunch crossing, with high signal efficiency and comparatively lower background rejection. The data harvested from the L1 trigger is typically more than experiment infrastructure can handle for permanent storage and offline data analysis. Therefore, more sophisticated software Higher Level Triggers (HLT) are usually implemented to further reduce the rate, using full-precision and finer granularity detector information. The maximum allowable acceptance rate L1 trigger is constrained by the detector read out, the speed of at which the HLT performs the more refined selection, and the rate at which the Data AcQuisition (DAQ) system can retrieve the data for permanent storage.  

%The DAQ bandwidth, which is determined by the available storage capabilities and computing power, is related to the maximum allowable trigger rate $R_{\mathrm{trigger}} ^ {max}$ as follows:

\input{sections/introduction/atlas-cms}
\input{sections/introduction/lhcb}
\input{sections/introduction/alice}