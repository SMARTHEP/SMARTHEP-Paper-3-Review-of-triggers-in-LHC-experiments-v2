\subsection{LHCb online tracking algorithms}

In this section we describe the LHCb reconstruction procedure as anexample of the processes involved in reconstructing event objects such as tracks. Similar processes take place in the reconstruction chains of the other LHC experiments with variations due to the specific detector architecture.
% The LHCb reconstruction procedure provides a clear example of the processes involved in reconstructing events and event objects. 

In HLT1, information from the three tracking detectorsâ€”Vertex Locator (VELO), Upstream Tracker (UT) and Scintillating Fibre (SciFi) Tracker 
\todo[inline]{Citations for tracking detectors needed}
are used to perform partial event reconstruction in the dedicated CUDA-based software framework Allen~\cite{LHCb_Allen_GPU}. 
\todo[inline]{Need to define partial event reconstruction}
For each sub-detector, many of the following processes must be performed: decoding of input into the global coordinate system; clustering of hits within a detection plane; combination of hits/clusters from different detection layers to form particle trajectories; fitting of track model to track candidates; vertex-finding between tracks.

In the VELO, reconstruction begins with the clustering of hits on each silicon plane, with a bit mask-based clustering algorithm operating in parallel across the local regions of each cluster. Straight-line tracks are then reconstructed, starting with seeds of three hits from consecutive silicon planes, extended to the remaining layers and fit with a simple Kalman filter (discussed further in Section~\ref{sec:Algorithms}). 
Finally, primary vertex (PV) candidates are identified and matched to the tracks. Rather than mapping tracks one-to-one with PV candidates, each track receives a per-candidate weight (corresponding to the likelihood it is associated to each PV candidate) to enable parallel computation. 

UT hits are instead assigned to extrapolated VELO tracks using a minimum momentum cut-off, with the track momentum calculated from the curvature between the straight-line VELO tracks and UT hits.

Tracks passing the VELO and UT are extrapolated to create a search window in the SciFi, where seeds of three hits in different layers are formed. A $\chi^2$ fit is performed on the seeds, and the best seeds are extrapolated to the remainder of the SciFi layers. Since the discrimination power of the three initial hits is limited, several seeds are extrapolated for each UT track, performing additional fits to select the best track per UT track. Hits in the muon systems are matched to extrapolated SciFi tracks according to the track parameters obtained in the previous steps~\cite{LHCb:2023hlw, LHCb_Allen_GPU}.

\todo[inline]{This reads as a description of an offline algorithm, and needs some more considerations or a bottom line that is specific of the reconstruction in trigger.}

\todo[inline]{Not sure how the paragraph below fits in here, consider removing?}
Another class of algorithms that is widely used at LHC experiments is Kalman filters (KFs). KFs are recursive algorithms used for state estimation and data fusion (i.e., combination of information from multiple sensors), with a well-established position as a key reconstruction tool~\cite{kalman-track}, and are particularly well-suited for problems involving dynamic (i.e.,  time-dependent) systems and noisy measurements. KFs combine information from previous state estimates and new measurements to provide an optimal estimate of the current state, taking into account both the dynamics of the system and the uncertainties associated with each measurement~\cite{FRUHWIRTH1987444}. KFs are employed across the major LHC experiments for the tracking of charged particles~\cite{Belikov:2003yr,ATLAS:tracking,CMS:tracking,LHCb_Allen_GPU}